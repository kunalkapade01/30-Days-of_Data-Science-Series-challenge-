{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be4d91b",
   "metadata": {},
   "source": [
    "# - 𝐆𝐞𝐧𝐞𝐫𝐚𝐭𝐢𝐯𝐞 𝐀𝐝𝐯𝐞𝐫𝐬𝐚𝐫𝐢𝐚𝐥 𝐍𝐞𝐭𝐰𝐨𝐫𝐤𝐬.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5b05a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kunal\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import library :\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091dd3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist datasets :\n",
    "(x_train, _), (_, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21a1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normlize the data :\n",
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
    "x_train = x_train.reshape(x_train.shape[0], 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692383dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kunal\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the generator model :\n",
    "generator = Sequential([\n",
    "    Dense(256, input_dim=100),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(512),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(1024),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(784, activation=\"tanh\"),\n",
    "    Reshape((28, 28))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff64662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the discriminator model:\n",
    "descriminator = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(1024),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(512),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f445501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the discriminator :\n",
    "descriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "                      loss=\"binary_crossentropy\", metrics=[\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd62abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the GAN model :\n",
    "descriminator.trainable = False\n",
    "gan_input = Input(shape=(100, ))\n",
    "x = generator(gan_input)\n",
    "gan_output = descriminator(x)\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "           loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcad284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the GAN :\n",
    "def train_gan(epochs=1, batch_size=128):\n",
    "    # Calculate the number of batches per epochs.\n",
    "    batch_count = x_train.shape[0] // batch_size\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for _ in range(batch_count):\n",
    "            # Generate random noise as input for the generator.\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "            \n",
    "            # Generate fake images from generator.\n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            # get random batch of real images from the dadasets.\n",
    "            batch_index = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            real_images = x_train[batch_index]\n",
    "            \n",
    "            # concatenate real and fake images.\n",
    "            x = np.concatenate([real_images, generated_images])\n",
    "            \n",
    "            # Labels for generated and real data.\n",
    "            y_dis = np.zeros(2 * batch_size)\n",
    "            y_dis[:batch_size] = 0.9     # one-sided label encoding.\n",
    "            \n",
    "            #Train the descriminator.\n",
    "            descriminator.trainable = True\n",
    "            d_los = descriminator.train_on_batch(x, y_dis)\n",
    "            \n",
    "            #Train the descriminator.in the generator (via the GAN model)\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            descriminator.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, y_gen)\n",
    "            \n",
    "            # Print the progress and save the generated iamges.\n",
    "            print(f\"Epoch {e+1}, Discriminatoe Loss: {d_los[0]}, Generator Loss: {g_loss}\")\n",
    "            if e % 10 == 0:\n",
    "                plot_generated_images(e, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afaa2c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Train the GAN model:\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m train_gan(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(epochs, batch_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m real_images \u001b[38;5;241m=\u001b[39m x_train[batch_index]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# concatenate real and fake images.\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([real_images, generated_images])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Labels for generated and real data.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m y_dis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m batch_size)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "# Function to plot generated images.\n",
    "def plot_generated_images(epoch, generator, example=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    noise = np.random.normal(0, 1, size=[example, 100])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(example, 28, 28)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(example):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation=\"nearest\", cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"gan_generated_image_epoch_{epoch}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "# Train the GAN model:\n",
    "train_gan(epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2235767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the GAN model:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_gan(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(epochs, batch_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m real_images \u001b[38;5;241m=\u001b[39m x_train[batch_index]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# concatenate real and fake images.\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([real_images, generated_images])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Labels for generated and real data.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m y_dis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m batch_size)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "# Train the GAN model:\n",
    "train_gan(epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7f8f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Train the GAN\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m train_gan(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 75\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(epochs, batch_size)\u001b[0m\n\u001b[0;32m     72\u001b[0m real_images \u001b[38;5;241m=\u001b[39m X_train[batch_idx]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Concatenate real and fake images\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([real_images, generated_images])\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Labels for generated and real data\u001b[39;00m\n\u001b[0;32m     78\u001b[0m y_dis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m batch_size)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = X_train.reshape(X_train.shape[0], 784)\n",
    "\n",
    "# Define the generator model\n",
    "generator = Sequential([\n",
    "    Dense(256, input_dim=100),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(512),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(1024),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(784, activation='tanh'),\n",
    "    Reshape((28, 28))\n",
    "])\n",
    "\n",
    "# Define the discriminator model\n",
    "discriminator = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(1024),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(512),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the discriminator\n",
    "discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "                      loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Compile the GAN model\n",
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(100,))\n",
    "x = generator(gan_input)\n",
    "gan_output = discriminator(x)\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "            loss='binary_crossentropy')\n",
    "\n",
    "# Function to train the GAN\n",
    "def train_gan(epochs=1, batch_size=128):\n",
    "    # Calculate the number of batches per epoch\n",
    "    batch_count = X_train.shape[0] // batch_size\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for _ in range(batch_count):\n",
    "            # Generate random noise as input for the generator\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "            \n",
    "            # Generate fake images using the generator\n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            # Get a random batch of real images from the dataset\n",
    "            batch_idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_images = X_train[batch_idx]\n",
    "            \n",
    "            # Concatenate real and fake images\n",
    "            X = np.concatenate([real_images, generated_images])\n",
    "            \n",
    "            # Labels for generated and real data\n",
    "            y_dis = np.zeros(2 * batch_size)\n",
    "            y_dis[:batch_size] = 0.9  # One-sided label smoothing\n",
    "            \n",
    "            # Train the discriminator\n",
    "            discriminator.trainable = True\n",
    "            d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            # Train the generator (via the GAN model)\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, y_gen)\n",
    "            \n",
    "        # Print the progress and save the generated images\n",
    "        print(f\"Epoch {e+1}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}\")\n",
    "        if e % 10 == 0:\n",
    "            plot_generated_images(e, generator)\n",
    "\n",
    "# Function to plot generated images\n",
    "def plot_generated_images(epoch, generator, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, 100])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(examples, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(examples):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'gan_generated_image_epoch_{epoch}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Train the GAN\n",
    "train_gan(epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c42df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
