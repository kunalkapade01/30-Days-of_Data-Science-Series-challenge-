{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e51d870",
   "metadata": {},
   "source": [
    "# - ğ‚ğ¨ğ§ğ¯ğ¨ğ¥ğ®ğ­ğ¢ğ¨ğ§ğšğ¥ ğğğ®ğ«ğšğ¥ ğğğ­ğ°ğ¨ğ«ğ¤ğ¬ (ğ‚ğğğ¬)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94f5239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kunal\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import Library:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb88fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist datasets :\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ed9ce",
   "metadata": {},
   "source": [
    "- ğğ«ğğ©ğ«ğ¨ğœğğ¬ğ¬ğ¢ğ§ğ  ğ­ğ¡ğ ğƒğšğ­ğš :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257d212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the data:\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype(\"float32\") / 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feaa115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kunal\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kunal\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a CNN model :\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16cf60ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kunal\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model :\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd7cf0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\kunal\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kunal\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "240/240 [==============================] - 16s 62ms/step - loss: 0.2996 - Accuracy: 0.9146 - val_loss: 0.0933 - val_Accuracy: 0.9729\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 0.0703 - Accuracy: 0.9780 - val_loss: 0.0614 - val_Accuracy: 0.9829\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.0491 - Accuracy: 0.9851 - val_loss: 0.0510 - val_Accuracy: 0.9854\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 0.0364 - Accuracy: 0.9889 - val_loss: 0.0450 - val_Accuracy: 0.9872\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 0.0309 - Accuracy: 0.9906 - val_loss: 0.0458 - val_Accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 0.0246 - Accuracy: 0.9927 - val_loss: 0.0417 - val_Accuracy: 0.9879\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.0208 - Accuracy: 0.9935 - val_loss: 0.0395 - val_Accuracy: 0.9893\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.0171 - Accuracy: 0.9946 - val_loss: 0.0422 - val_Accuracy: 0.9893\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.0148 - Accuracy: 0.9953 - val_loss: 0.0420 - val_Accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 0.0113 - Accuracy: 0.9966 - val_loss: 0.0382 - val_Accuracy: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22008bfcd10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model :\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=200, validation_split=0.2,\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd5192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute the model:\n",
    "loass, accuracy = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bbf8cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9904000163078308\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79407c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03078807331621647\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss: {loass}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206a4a34",
   "metadata": {},
   "source": [
    "- ğ„ğ±ğšğ¦ğ©ğ¥ğ ğ°ğ¢ğ­ğ¡ ğƒğšğ­ğš ğ€ğ®ğ ğ¦ğğ§ğ­ğšğ­ğ¢ğ¨ğ§ ğšğ§ğ ğƒğ«ğ¨ğ©ğ¨ğ®ğ­ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c989822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library :\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da4069e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augementation:\n",
    "DataGen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e08b79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creat CNN model with Dropout :\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0a4b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the train the model :\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17fd30f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 76s 242ms/step - loss: 0.7437 - Accuracy: 0.7565 - val_loss: 0.0987 - val_Accuracy: 0.9697\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 65s 217ms/step - loss: 0.3039 - Accuracy: 0.9074 - val_loss: 0.0557 - val_Accuracy: 0.9813\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 65s 215ms/step - loss: 0.2299 - Accuracy: 0.9295 - val_loss: 0.0418 - val_Accuracy: 0.9874\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 62s 207ms/step - loss: 0.1966 - Accuracy: 0.9403 - val_loss: 0.0334 - val_Accuracy: 0.9890\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 70s 233ms/step - loss: 0.1638 - Accuracy: 0.9500 - val_loss: 0.0276 - val_Accuracy: 0.9904\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 66s 221ms/step - loss: 0.1508 - Accuracy: 0.9541 - val_loss: 0.0255 - val_Accuracy: 0.9912\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 66s 221ms/step - loss: 0.1387 - Accuracy: 0.9585 - val_loss: 0.0228 - val_Accuracy: 0.9912\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 69s 230ms/step - loss: 0.1312 - Accuracy: 0.9596 - val_loss: 0.0225 - val_Accuracy: 0.9918\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 66s 219ms/step - loss: 0.1204 - Accuracy: 0.9644 - val_loss: 0.0218 - val_Accuracy: 0.9922\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 72s 238ms/step - loss: 0.1101 - Accuracy: 0.9666 - val_loss: 0.0197 - val_Accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22011baefd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model :\n",
    "model.fit(DataGen.flow(x_train, y_train, batch_size=200), epochs=10,\n",
    "         validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631fbc54",
   "metadata": {},
   "source": [
    "- ğ‚ğ¨ğ§ğœğğ©ğ­ :\n",
    "ğ‚ğ¨ğ§ğ¯ğ¨ğ¥ğ®ğ­ğ¢ğ¨ğ§ğšğ¥ ğğğ®ğ«ğšğ¥ ğğğ­ğ°ğ¨ğ«ğ¤ğ¬ (ğ‚ğğğ¬) are specialized neural networks designed to process data with a grid-like topology, such as images. They are particularly effective for image recognition and classification tasks due to their ability to capture spatial hierarchies in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0536114",
   "metadata": {},
   "source": [
    "ğŠğğ² ğ…ğğšğ­ğ®ğ«ğğ¬ ğ¨ğŸ ğ‚ğğğ¬ :\n",
    "\n",
    "- ğ‚ğ¨ğ§ğ¯ğ¨ğ¥ğ®ğ­ğ¢ğ¨ğ§ğšğ¥ ğ‹ğšğ²ğğ«ğ¬: Apply convolution operations to extract features from the input data.\n",
    "- ğğ¨ğ¨ğ¥ğ¢ğ§ğ  ğ‹ğšğ²ğğ«ğ¬: Reduce the dimensionality of the data while retaining important features.\n",
    "- ğ…ğ®ğ¥ğ¥ğ² ğ‚ğ¨ğ§ğ§ğğœğ­ğğ ğ‹ğšğ²ğğ«ğ¬: Perform classification based on the extracted features.\n",
    "- ğ€ğœğ­ğ¢ğ¯ğšğ­ğ¢ğ¨ğ§ ğ…ğ®ğ§ğœğ­ğ¢ğ¨ğ§ğ¬: Introduce non-linearity to the network (e.g., ReLU).\n",
    "- ğ…ğ¢ğ¥ğ­ğğ«ğ¬/ğŠğğ«ğ§ğğ¥ğ¬: Learnable parameters that detect specific patterns like edges, textures, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5ac08",
   "metadata": {},
   "source": [
    "ğŠğğ² ğ’ğ­ğğ©ğ¬ :\n",
    "\n",
    "- ğ‚ğ¨ğ§ğ¯ğ¨ğ¥ğ®ğ­ğ¢ğ¨ğ§ ğğ©ğğ«ğšğ­ğ¢ğ¨ğ§: Slide filters over the input image to create feature maps.\n",
    "- ğğ¨ğ¨ğ¥ğ¢ğ§ğ  ğğ©ğğ«ğšğ­ğ¢ğ¨ğ§: Downsample the feature maps to reduce dimensions and computation.\n",
    "- ğ…ğ¥ğšğ­ğ­ğğ§ğ¢ğ§ğ : Convert the 2D feature maps into a 1D vector for the fully connected layers.\n",
    "- ğ…ğ®ğ¥ğ¥ğ² ğ‚ğ¨ğ§ğ§ğğœğ­ğğ ğ‹ğšğ²ğğ«ğ¬: Perform the final classification based on the extracted features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376c86c",
   "metadata": {},
   "source": [
    "ğ€ğğ¯ğšğ§ğœğğ ğ…ğğšğ­ğ®ğ«ğğ¬ ğ¨ğŸ ğ‚ğğğ¬ :\n",
    "\n",
    "1. ğƒğğğ©ğğ« ğ€ğ«ğœğ¡ğ¢ğ­ğğœğ­ğ®ğ«ğğ¬: Increase the number of convolutional and pooling layers for better feature extraction.\n",
    "2. ğƒğšğ­ğš ğ€ğ®ğ ğ¦ğğ§ğ­ğšğ­ğ¢ğ¨ğ§: Enhance the training set by applying transformations like rotation, flipping, and scaling.\n",
    "3. ğ“ğ«ğšğ§ğ¬ğŸğğ« ğ‹ğğšğ«ğ§ğ¢ğ§ğ : Use pre-trained models (e.g., VGG, ResNet) and fine-tune them on specific tasks.\n",
    "4. ğ‘ğğ ğ®ğ¥ğšğ«ğ¢ğ³ğšğ­ğ¢ğ¨ğ§ ğ“ğğœğ¡ğ§ğ¢ğªğ®ğğ¬: \n",
    "   - ğƒğ«ğ¨ğ©ğ¨ğ®ğ­: Randomly drop neurons during training to prevent overfitting.\n",
    "   - ğğšğ­ğœğ¡ ğğ¨ğ«ğ¦ğšğ¥ğ¢ğ³ğšğ­ğ¢ğ¨ğ§: Normalize inputs of each layer to stabilize and accelerate training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f8cac",
   "metadata": {},
   "source": [
    "ğ€ğ©ğ©ğ¥ğ¢ğœğšğ­ğ¢ğ¨ğ§ğ¬ :\n",
    "\n",
    "CNNs are widely used in various fields such as:\n",
    "- ğ‚ğ¨ğ¦ğ©ğ®ğ­ğğ« ğ•ğ¢ğ¬ğ¢ğ¨ğ§: Image classification, object detection, facial recognition.\n",
    "- ğŒğğğ¢ğœğšğ¥ ğˆğ¦ğšğ ğ¢ğ§ğ : Tumor detection, medical image segmentation.\n",
    "- ğ€ğ®ğ­ğ¨ğ§ğ¨ğ¦ğ¨ğ®ğ¬ ğƒğ«ğ¢ğ¯ğ¢ğ§ğ : Road sign recognition, obstacle detection.\n",
    "- ğ€ğ®ğ ğ¦ğğ§ğ­ğğ ğ‘ğğšğ¥ğ¢ğ­ğ²: Gesture recognition, object tracking.\n",
    "- ğ’ğğœğ®ğ«ğ¢ğ­ğ²: Surveillance, biometric authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0955088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
